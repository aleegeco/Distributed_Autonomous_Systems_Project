{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24fa964",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#  WARNING, EXECUTE THIS LINE BEFORE EXEsCUTING ANY ROS CODE #\n",
    "#                                                            #\n",
    "#             source opt/ros/foxy/setup.bash                 #\n",
    "#                                                            #\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ede3818",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 23:55:42.864131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-24 23:55:42.864175: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function# need to undestend their utility <-------- UNKNOWN\n",
    "import tensorflow as tf\n",
    "import keras# dont import keras ftom tensorflow library otherwise the code below will fail\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras_visualizer import visualizer# used to visualize the neural network <-------------------- MORE INFORMATION\n",
    "from tensorflow.keras.utils import plot_model# used to plot the neural network model <------------------MORE INFO\n",
    "import matplotlib.pyplot as plt# this library will be used for data visualization\n",
    "\n",
    "TestSize = 0.1# size of the test set\n",
    "\n",
    "percent = 0.2# percentage of data we want to give to our system from all the data aveilable\n",
    "# we start to take them from the start of the dataset , one after one)\n",
    "\n",
    "LukyNumber = 4# the number that in this session will be associated to 1 while the others will be set to 0\n",
    "# (we set all the other numbers to zero becouse otherwise the neural network behave incorrectly with thos libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060d4704",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# import the dataset \"mnist\" that contains all the images of the numbers\n",
    "# and relatives lables an then assine all those data to two sets ( training set and test set )\n",
    "\n",
    "# adjusting the type of the data contained in the arrays\n",
    "y_train = y_train.astype(np.int8)\n",
    "y_test = y_test.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248c7c9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "60000\n",
      "(60000, 28, 28)\n",
      "<class 'numpy.ndarray'>\n",
      "10000\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# I want to see some information about my data and they format\n",
    "print(type(x_train))# return the typology of our data set of images\n",
    "print(len(x_train))# retunr the lenth of the data set ( how much images we have )\n",
    "print(np.shape(x_train))# return the shape of the data set, in our case we have the\n",
    "# lenth and then the dimensions of the images\n",
    "\n",
    "print(type(x_test))# return the typology of our training set of images\n",
    "print(len(x_test))# retunr the lenth of the training set ( how much images we have )\n",
    "print(np.shape(x_test))# return the shape of the training set, in our case we have the\n",
    "# lenth and then the dimensions of the images\n",
    "\n",
    "#print(dir(np))\n",
    "#print(help(np.concatenate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ee9fb9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_total_temp: (70000, 28, 28)\n",
      "Shape of x_total reduced to 0.2: (14000, 28, 28)\n",
      "Shape of y_total_temp: (70000,)\n",
      "Shape of y_total reduced to 0.2: (14000,)\n"
     ]
    }
   ],
   "source": [
    "'''                             I HAVE TO CHECK IF THIS PART OF THE CODE IS CORRECT                            '''\n",
    "\n",
    "#                                    Reduction of the dataset dimension\n",
    "\n",
    "x_total_temp = np.append(x_train, x_test, axis=0)# CHECK IF THE PARTS ARE APPENDED CORRECTLY <------------- WARNING\n",
    "print(\"Shape of x_total_temp: {0}\".format(np.shape(x_total_temp)))\n",
    "\n",
    "x_total = x_total_temp[0: int(np.shape(x_total_temp)[0]*percent)]\n",
    "print(\"Shape of x_total reduced to {1}: {0}\".format(np.shape(x_total), percent))\n",
    "\n",
    "y_total_temp = np.append(y_train, y_test, axis=0)# CHECK IF THE PARTS ARE APPENDED CORRECTLY <------------- WARNING\n",
    "print(\"Shape of y_total_temp: {0}\".format(np.shape(y_total_temp)))\n",
    "\n",
    "y_total = y_total_temp[0: int(np.shape(y_total_temp)[0]*percent)]\n",
    "print(\"Shape of y_total reduced to {1}: {0}\".format(np.shape(y_total), percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429bfe16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"                                       THE ERROR COULD BE HERE                                                \"\"\"\n",
    "# Redistribution of the data in two sets ( test and train)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_total, y_total, test_size=TestSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672f5a2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int8\n"
     ]
    }
   ],
   "source": [
    "\"\"\"                                       THE ERROR COULD BE HERE                                                \"\"\"\n",
    "#                                     Assignment of values [1, -1]\n",
    "\n",
    "# REWRITE THE CODE BECAUSE IT ISNT EFFISCENT ENOUGH (nested for loops or something else)\n",
    "\n",
    "for i in range(0, np.shape(y_train)[0]):# <-------------------------------------------------- WARNING (use iterator)\n",
    "    if y_train[i] == LukyNumber:\n",
    "        y_train[i] = 1\n",
    "    else:\n",
    "        y_train[i] = -1\n",
    "        \n",
    "for i in range(0, np.shape(y_test)[0]):# <-------------------------------------------------- WARNING (use iterator)\n",
    "    if y_test[i] == LukyNumber:\n",
    "        y_test[i] = 1\n",
    "    else:\n",
    "        y_test[i] = -1\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db5d945",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth of y_train : 12600\n",
      "\n",
      "Shape of y_train : (12600,)\n",
      "\n",
      "y_training : [-1 -1 -1 ... -1 -1 -1]\n",
      "\n",
      "Lenth of y_test : 1400\n",
      "\n",
      "Shape of y_test : (1400,)\n",
      "\n",
      "y_test : [-1 -1 -1 ... -1  1 -1]\n",
      "\n",
      "Lenth of x_train : 12600\n",
      "\n",
      "Shape of x_train : (12600, 28, 28)\n",
      "\n",
      "x_train : [[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "\n",
      "Lenth of x_test : 1400\n",
      "\n",
      "Shape of x_test : (1400, 28, 28)\n",
      "\n",
      "x_test : [[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST TO SEE THE SHAPE OF THE DATA\n",
    "print(\"Lenth of y_train : {}\\n\".format(len(y_train)))\n",
    "print(\"Shape of y_train : {}\\n\".format(np.shape(y_train)))\n",
    "print(\"y_training : {}\\n\".format(y_train))\n",
    "\n",
    "print(\"Lenth of y_test : {}\\n\".format(len(y_test)))\n",
    "print(\"Shape of y_test : {}\\n\".format(np.shape(y_test)))\n",
    "print(\"y_test : {}\\n\".format(y_test))\n",
    "\n",
    "# I WANT TO SEE THE SHAPE OF PICTURES\n",
    "print(\"Lenth of x_train : {}\\n\".format(len(x_train)))\n",
    "print(\"Shape of x_train : {}\\n\".format(np.shape(x_train)))\n",
    "print(\"x_train : {}\\n\".format(x_train))\n",
    "\n",
    "print(\"Lenth of x_test : {}\\n\".format(len(x_test)))\n",
    "print(\"Shape of x_test : {}\\n\".format(np.shape(x_test)))\n",
    "print(\"x_test : {}\\n\".format(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f9b6ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the first 25 training images with labels and verify that the data is in the correct formate.\n",
    "plt.figure(figsize=(10,10))# <--------------------------------------------------------------------------- UNKNOWN\n",
    "for i in range(25):# i want to plot 25 images\n",
    "    plt.subplot(5,5,i+1)# the letter \"i\" rappresent the position \n",
    "    plt.xticks([])# <------------------------------------------------------------------------------------ UNKNOWN\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)# in this way i will not have the grid in on the images\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)# load the image and make it show black and white\n",
    "    plt.xlabel(y_train[i])# add the lable associated to that image under it\n",
    "plt.show()# show all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c7f24b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth of y_training : 12600\n",
      "\n",
      "Shape of y_training : (12600,)\n",
      "\n",
      "y_training : [-1 -1 -1 ... -1 -1 -1]\n",
      "\n",
      "Lenth of x_training : 12600\n",
      "\n",
      "Shape of x_training : (12600, 784)\n",
      "\n",
      "x_training : [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HERE I RESHAPE THE IMAGES FROM A MATRIX TO A VECTOR MANTAINING THE DATA CONTENT\n",
    "SrecchedDatasetX = np.reshape(x_train, (np.shape(x_train)[0], 784))# the dataset has 11200 elements, you have to make this part of code more general\n",
    "\n",
    "# TEST TO SEE THE SHAPE OF THE DATA\n",
    "print(\"Lenth of y_training : {}\\n\".format(len(y_train)))\n",
    "print(\"Shape of y_training : {}\\n\".format(np.shape(y_train)))\n",
    "print(\"y_training : {}\\n\".format(y_train))\n",
    "\n",
    "# I WANT TO SEE THE SHAPE OF PICTURES\n",
    "print(\"Lenth of x_training : {}\\n\".format(len(SrecchedDatasetX)))\n",
    "print(\"Shape of x_training : {}\\n\".format(np.shape(SrecchedDatasetX)))\n",
    "print(\"x_training : {}\\n\".format(SrecchedDatasetX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb9839b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAEMCAYAAADEcgMjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMk0lEQVR4nO3df6jd9X3H8eerGhP81SZzzVKntRPHkMHiuNiyynBIO9d/1H9cZUhKS+MfChU6mPiP/jOQrdr1D7HEKU2ZdQjqFOa6hlCwhWGNEkw0Xe1KpIaYVDJQ1xmjee+P+9Vd7b3n3txzzvd74uf5gHDP/X7Pueft1+SZ7/d7vjknVYWkdn1k6AEkDcsISI0zAlLjjIDUOCMgNc4ISI0bJAJJrkzyn0l+nuSWIWYYJcn+JHuS7E6yawbmuT/J4SR7FyzbkGRHkhe7r+tnbL7bkxzotuHuJF8YcL7zkvwwyQtJnk/ytW75TGzDEfP1sg3T93UCSU4BfgZ8DngZeBq4rqpe6HWQEZLsB+aq6tWhZwFI8qfAG8B3q+oPu2V/Bxypqju6kK6vqr+ZofluB96oqm8MMdNCSTYBm6rq2SRnAc8AVwNfYga24Yj5rqWHbTjEnsClwM+r6hdV9Rbwz8BVA8xx0qiqJ4EjH1h8FbC9u72d+d80g1hivplRVQer6tnu9uvAPuBcZmQbjpivF0NE4Fzglwu+f5ke/4NXqIAfJHkmydahh1nCxqo62N1+Bdg45DBLuCnJc93hwmCHKwsluQC4BHiKGdyGH5gPetiGnhhc3GVV9cfAXwA3dru7M6vmj+lm7frve4ALgc3AQeDOQacBkpwJPAzcXFWvLVw3C9twkfl62YZDROAAcN6C73+3WzYzqupA9/Uw8CjzhzCz5lB3LPnuMeXhged5n6o6VFXvVNVx4F4G3oZJ1jD/B+yBqnqkWzwz23Cx+frahkNE4GngoiSfSnIa8EXg8QHmWFSSM7qTMyQ5A/g8sHf0owbxOLClu70FeGzAWX7Du3+4Otcw4DZMEuA+YF9V3bVg1Uxsw6Xm62sb9v7qAED3Usc/AKcA91fV3/Y+xBKS/B7zf/sDnAp8b+j5kjwIXA6cAxwCbgP+BXgIOB94Cbi2qgY5ObfEfJczvxtbwH7ghgXH333PdxnwI2APcLxbfCvzx92Db8MR811HD9twkAhImh2eGJQaZwSkxhkBqXFGQGqcEZAaN2gEZviSXMD5xjXL883ybNDvfEPvCcz0/wicb1yzPN8szwY9zjd0BCQNbKyLhZJcCXyL+Sv//rGq7hh1/9OyttZxxnvfH+Moa1i76uefNucbzyzPN8uzweTne5P/4a06msXWrToCq3lzkLOzoT6dK1b1fJJW76nayWt1ZNEIjHM44JuDSB8C40TgZHhzEEnLOHXaT9C91LEVYB2nT/vpJJ2gcfYEVvTmIFW1rarmqmpulk/ESK0aJwIz/eYgklZm1YcDVfV2kpuAf+f/3xzk+YlNJqkXY50TqKongCcmNIukAXjFoNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1bqyPJteHS04d/dvhxb+fG7n+v/7y2yPX//nV148e4Cd7Rq/XVIwVgST7gdeBd4C3q2r07xJJM2cSewJ/VlWvTuDnSBqA5wSkxo0bgQJ+kOSZJFsXu0OSrUl2Jdl1jKNjPp2kSRv3cOCyqjqQ5OPAjiQ/raonF96hqrYB2wDOzoYa8/kkTdhYewJVdaD7ehh4FLh0EkNJ6s+qI5DkjCRnvXsb+Dywd1KDSerHOIcDG4FHk7z7c75XVd+fyFQaRM1dPHL9T6+9e+T6Y8sc7B39rXUj168d/XBNyaojUFW/AP5ogrNIGoAvEUqNMwJS44yA1DgjIDXOCEiNMwJS43w/AfXm0JffHLn+/H/raRC9j3sCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zs8dUH/2nDX0BFrEsnsCSe5PcjjJ3gXLNiTZkeTF7uv66Y4paVpWcjjwHeDKDyy7BdhZVRcBO7vvJZ2Elo1AVT0JHPnA4quA7d3t7cDVkx1LUl9We05gY1Ud7G6/Amxc6o5JtgJbAdZx+iqfTtK0jP3qQFUVUCPWb6uquaqaW8PacZ9O0oStNgKHkmwC6L4entxIkvq02gg8Dmzpbm8BHpvMOJL6tuw5gSQPApcD5yR5GbgNuAN4KMlXgJeAa6c5pD4czv/+60OPoEUsG4Gqum6JVVdMeBZJA/CyYalxRkBqnBGQGmcEpMYZAalxRkBqnO8noN788nOj30/gvJ/0NIjexz0BqXFGQGqcEZAaZwSkxhkBqXFGQGqcEZAa53UC6s3/nn9s6BG0CPcEpMYZAalxRkBqnBGQGmcEpMYZAalxRkBqnNcJqDe/f9+bQ4+gRbgnIDXOCEiNMwJS44yA1DgjIDXOCEiNMwJS44yA1LhlI5Dk/iSHk+xdsOz2JAeS7O5+fWG6Y0qalpXsCXwHuHKR5d+sqs3drycmO5akviwbgap6EjjSwyySBjDOOYGbkjzXHS6sX+pOSbYm2ZVk1zGOjvF0kqZhtRG4B7gQ2AwcBO5c6o5Vta2q5qpqbg1rV/l0kqZlVRGoqkNV9U5VHQfuBS6d7FiS+rKqCCTZtODba4C9S91X0mxb9v0EkjwIXA6ck+Rl4Dbg8iSbgQL2AzdMb0SdLP711x8duf6UI2+MXP/OJIfRii0bgaq6bpHF901hFkkD8IpBqXFGQGqcEZAaZwSkxhkBqXFGQGqcnzugifmTdYdGrv/2Waf3NIlOhHsCUuOMgNQ4IyA1zghIjTMCUuOMgNQ4IyA1zusENDF/9bMvjlz/kd0v9DSJToR7AlLjjIDUOCMgNc4ISI0zAlLjjIDUOCMgNc7rBPSetz423sfEvX189N8pp1WN9fM1He4JSI0zAlLjjIDUOCMgNc4ISI0zAlLjjIDUOK8T0HsOf/XXYz3+wKsfG7n+U7w01s/XdCy7J5DkvCQ/TPJCkueTfK1bviHJjiQvdl/XT39cSZO2ksOBt4GvV9XFwGeAG5NcDNwC7Kyqi4Cd3feSTjLLRqCqDlbVs93t14F9wLnAVcD27m7bgaunNKOkKTqhcwJJLgAuAZ4CNlbVwW7VK8DGJR6zFdgKsA4/i06aNSt+dSDJmcDDwM1V9drCdVVVwKL/OqSqtlXVXFXNrWG8f6AiafJWFIEka5gPwANV9Ui3+FCSTd36TcDh6YwoaZpW8upAgPuAfVV114JVjwNbuttbgMcmP56kaVvJOYHPAtcDe5Ls7pbdCtwBPJTkK8BLwLVTmVAnjU/802lDj6BVWDYCVfVjIEusvmKy40jqm5cNS40zAlLjjIDUOCMgNc4ISI0zAlLjjIDUOCMgNc4ISI0zAlLjjIDUOCMgNc4ISI0zAlLjjIDUOCMgNc4ISI0zAlLjjIDUOCMgNc4ISI0zAlLjTuizCPUht+ujo9d/pp8x1C/3BKTGGQGpcUZAapwRkBpnBKTGGQGpcUZAalyqavQdkvOA7wIbgQK2VdW3ktwOfBX4VXfXW6vqiVE/6+xsqE/HTzOX+vZU7eS1OpLF1q3kYqG3ga9X1bNJzgKeSbKjW/fNqvrGpAaV1L9lI1BVB4GD3e3Xk+wDzp32YJL6cULnBJJcAFwCPNUtuinJc0nuT7J+0sNJmr4VRyDJmcDDwM1V9RpwD3AhsJn5PYU7l3jc1iS7kuw6xtHxJ5Y0USuKQJI1zAfggap6BKCqDlXVO1V1HLgXuHSxx1bVtqqaq6q5Nayd1NySJmTZCCQJcB+wr6ruWrB804K7XQPsnfx4kqZtJa8OfBa4HtiTZHe37FbguiSbmX/ZcD9wwxTmkzRlK3l14MfAYq8vjrwmQNLJwSsGpcYZAalxRkBqnBGQGmcEpMYZAalxRkBqnBGQGmcEpMYZAalxRkBqnBGQGmcEpMYZAalxRkBq3LKfOzDRJ0t+Bby0YNE5wKu9DXDinG88szzfLM8Gk5/vk1X124ut6DUCv/Hkya6qmhtsgGU433hmeb5Zng36nc/DAalxRkBq3NAR2Dbw8y/H+YAkf5DkP5IcTfLXJ/DQWd5+szwb9DjfoOcEdHJI8nHgk8DVwH/7+ZMfLkPvCegkUFWHq+pp4NjQs2jyjIDUOCMgNc4IaFFJbkyyu/v1iaHn0fSs5GPI1KCquhu4e+g5NH2+OqBlJfkdYBdwNnAceAO4uPuIep3kjIDUOM8JSI0zAlLjjIDUOCMgNc4ISI0zAlLjjIDUOCMgNe7/AOrydupERmS+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HERE I TEST THE CONVERSION GOING BACKWARD (CHEKING IF THE IMAGE IS CORRECT)\n",
    "#print(SrecchedDatasetX[1])\n",
    "prova = np.reshape(SrecchedDatasetX[int(0)], (28, 28))# here at index you can put whatewer number you wish to see if the conversion went correctly\n",
    "plt.matshow(prova)\n",
    "plt.xlabel(y_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472451d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The erlier part was a preprocessing of the data, now we will use distributed gradient traking for the training of the neural network.\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f9929d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# example \n",
    "def adder(a: float, b: float) -> float:\n",
    "    return float(a+b)\n",
    "#type(adder(3, 5))\n",
    "\n",
    "#NNShape = np.array([784, 10, 10, 10, 1])\n",
    "#a = np.zeros(tuple(NNShape))\n",
    "#print(\"\\nshape of a: {0}\".format(np.shape(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e5fa1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5272/3278228246.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-xi))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at k=0 is 0.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 163>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;66;03m# Backward propagation\u001B[39;00m\n\u001B[1;32m    168\u001B[0m llambdaT \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m( xx[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m label_point[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;66;03m# xT . LambdaT = 2*(-LablePoint)\u001B[39;00m\n\u001B[0;32m--> 169\u001B[0m Delta_u \u001B[38;5;241m=\u001B[39m \u001B[43mbackward_pass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxx\u001B[49m\u001B[43m,\u001B[49m\u001B[43muu\u001B[49m\u001B[43m,\u001B[49m\u001B[43mllambdaT\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# the gradient of the loss function \u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# Update the weights\u001B[39;00m\n\u001B[1;32m    172\u001B[0m uu \u001B[38;5;241m=\u001B[39m uu \u001B[38;5;241m-\u001B[39m stepsize\u001B[38;5;241m*\u001B[39mDelta_u \u001B[38;5;66;03m# overwriting the old value\u001B[39;00m\n",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36mbackward_pass\u001B[0;34m(xx, uu, llambdaT)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward_pass\u001B[39m(xx,uu,llambdaT):\n\u001B[1;32m    116\u001B[0m   \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;124;03m    input: \u001B[39;00m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;124;03m              xx state trajectory: x[1],x[2],..., x[T]\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;124;03m              delta_u costate output, i.e., the loss gradient\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 125\u001B[0m   llambda \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[43mT\u001B[49m,d))\n\u001B[1;32m    126\u001B[0m   llambda[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m llambdaT\n\u001B[1;32m    128\u001B[0m   Delta_u \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((T\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,d,d\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "# https://ojs.aaai.org/index.php/AAAI/article/download/7178/7032\n",
    "###############################################################################\n",
    "\n",
    "# this array rappresents the shape of our neural network\n",
    "# each i-th element of the array says how much neurons has that layer\n",
    "# the first layer has 784 neurons becouse is the layer rappresenting the vectorazed image\n",
    "# the last layer is composed by one neuron becouse it will say if the image contains the LukyNumber or not\n",
    "NNShape = np.array([784, 10, 10, 10, 1])\n",
    "\n",
    "# Training Set\n",
    "label_point = y_train # D = x0\n",
    "data_point = SrecchedDatasetX # y = xT = phi (ustar)\n",
    "\n",
    "# Gradient Method Parameters\n",
    "max_iters = 10 # epochs\n",
    "stepsize = 0.1 # learning rate\n",
    "\n",
    "###############################################################################\n",
    "# Activation Function\n",
    "def sigmoid_fn(xi: float) -> float:\n",
    "  return 1/(1+np.exp(-xi))\n",
    "\n",
    "# Derivative of Activation Function\n",
    "def sigmoid_fn_derivative(xi: float) -> float:\n",
    "  return sigmoid_fn(xi)*(1-sigmoid_fn(xi))\n",
    "\n",
    "# Calculate the output of one layer of neurons given the input of previous layer and the weiths\n",
    "def inference_dynamics(xt: np.array, ut: np.array, d: np.array, WhereIAm: int) -> np.array:\n",
    "  \"\"\"\n",
    "    input: \n",
    "              xt -> previous layer resoults\n",
    "              ut -> current layer weiths\n",
    "              d  -> array containing the number of nodes of each layer\n",
    "              WhereIAm -> integer that says which layer you have selected now\n",
    "    output: \n",
    "              xtp -> output of this layer\n",
    "  \"\"\"\n",
    "  # allocate space for the output ( input of the next layer )\n",
    "  xtp = np.zeros(d[WhereIAm+1])# here i am looking for the number of neurons of the next layer\n",
    "\n",
    "  #print(\"WhereIAm: {0}\\n\".format(WhereIAm))\n",
    "  #print(\"shape of xtp: {0}\\n\".format(np.shape(xtp)))\n",
    "  #print(\"shape of d[WhereIAm]: {0}\\n\".format(np.shape(d)))\n",
    "  #print(\"shape of xt: {0}\\n\".format(np.shape(xt)))\n",
    "  #print(\"shape of ut: {0}\\n\".format(np.shape(ut)))\n",
    "\n",
    "  #print(\"xtp: {0}\\n\".format(xtp))\n",
    "  #print(\"d[WhereIAm]: {0}\\n\".format(d[WhereIAm]))\n",
    "  #print(\"xt: {0}\\n\".format(xt))\n",
    "  #print(\"ut: {0}\\n\".format(ut))\n",
    "  for ell in range(d[WhereIAm+1]):# for each node of this layer compute those operations\n",
    "    temp = xt@ut[ell,:]# calculate the output of the neuron including the bias\n",
    "    xtp[ell] = sigmoid_fn(temp) # x' * u_ell. . Calculate the output of one neuron and put it in the next layer\n",
    "  return xtp\n",
    "\n",
    "# Calculation of layers of neurons output for each layer untill the end\n",
    "def forward_pass(uu: list, x0: np.array, d: np.array) -> list:\n",
    "  \"\"\"\n",
    "    input: \n",
    "              uu -> tensor containing all the weiths of the neural network\n",
    "              x0 -> input of neural network (in this case the vectorized image)\n",
    "              d -> array containing the number of nodes of each layer\n",
    "    output: \n",
    "              xx -> output of our neurla network\n",
    "  \"\"\"\n",
    "  # allocate the memory for the resoults of the whole neural network.\n",
    "  xx = list()# here i create a tensor of shape [784, 10, 10, 10, 1] containing only zeros\n",
    "  for i in range(0, len(d)):# i start from 1 becouse in the layer zero we ahve the vectorized image\n",
    "    xx.append(np.zeros(d[i]))\n",
    "    \n",
    "  xx[0] = x0# this is the first layer of the neural network. It has to bee the image (vector rappresenting the image)\n",
    "\n",
    "  for t in range(np.shape(d)[0]-1):\n",
    "    # calculate the resoults of the computation of the whole neural network\n",
    "    xx[t+1] = inference_dynamics(xx[t],uu[t], d, t)# i put t becouse we skip the firs layer ?\n",
    "  return xx\n",
    "  \n",
    "\n",
    "'''\n",
    "# Adjoint dynamics: \n",
    "#   state:    lambda_t = A.T lambda_tp\n",
    "#   output: deltau_t = B.T lambda_tp\n",
    "def adjoint_dynamics(ltp,xt,ut):\n",
    "  \"\"\"\n",
    "    input: \n",
    "              llambda_tp current costate\n",
    "              xt current state\n",
    "              ut current input\n",
    "    output: \n",
    "              llambda_t next costate\n",
    "              delta_ut loss gradient wrt u_t\n",
    "  \"\"\"\n",
    "  df_dx = np.zeros((d,d))\n",
    "\n",
    "  # df_du = np.zeros((d,(d+1)*d))\n",
    "  Delta_ut = np.zeros((d,d+1))\n",
    "\n",
    "  for j in range(d):\n",
    "    dsigma_j = sigmoid_fn_derivative(xt@ut[j,1:] + ut[j,0]) \n",
    "\n",
    "    df_dx[:,j] = ut[j,1:]*dsigma_j\n",
    "    # df_du[j, XX] = dsigma_j*np.hstack([1,xt])\n",
    "    \n",
    "    # B'@ltp\n",
    "    Delta_ut[j,0] = ltp[j]*dsigma_j\n",
    "    Delta_ut[j,1:] = xt*ltp[j]*dsigma_j\n",
    "  \n",
    "  lt = df_dx@ltp # A'@ltp\n",
    "  # Delta_ut = df_du@ltp\n",
    "\n",
    "  return lt, Delta_ut\n",
    "'''\n",
    "\n",
    "# Backward Propagation\n",
    "def backward_pass(xx: list,uu: list, llambdaT: float):\n",
    "  \"\"\"\n",
    "    input: \n",
    "              xx state trajectory: x[1],x[2],..., x[T]\n",
    "              uu input trajectory: u[0],u[1],..., u[T-1]\n",
    "              llambdaT terminal condition\n",
    "    output: \n",
    "              llambda costate trajectory\n",
    "              delta_u costate output, i.e., the loss gradient\n",
    "  \"\"\"\n",
    "  llambda = np.zeros((T,d))\n",
    "  llambda[-1] = llambdaT\n",
    "\n",
    "  Delta_u = np.zeros((T-1,d,d+1))\n",
    "\n",
    "  for t in reversed(range(T-1)): # T-2,T-1,...,1,0\n",
    "    llambda[t], Delta_u[t] = adjoint_dynamics(llambda[t+1],xx[t],uu[t])\n",
    "\n",
    "  return Delta_u\n",
    "\n",
    "  \n",
    "###############################################################################\n",
    "# MAIN\n",
    "###############################################################################\n",
    "\n",
    "J = np.zeros(max_iters)                       # Vector containing the evolution of the cost\n",
    "\n",
    "ListContainingWeithsTensor = list()# -> it is a list containing the matrices used for inference dynamics\n",
    "for i in range(0, len(NNShape)-1):\n",
    "    ListContainingWeithsTensor.append(np.random.randn(NNShape[i+1], NNShape[i]))\n",
    "    \n",
    "def GetTensorWeithsData(ListOfMatrices: list) -> None:\n",
    "    print(\"The lenth of the List of matrices is {0}\".format(len(ListContainingWeithsTensor)))\n",
    "    print(\"It's type is: {0}\\n\".format(type(ListContainingWeithsTensor)))\n",
    "    for i in range(0, len(ListOfMatrices)):\n",
    "        print(\"The type of {0} element is {1}\".format(i, type(ListContainingWeithsTensor[i])))\n",
    "        print(\"While the shape is {0}\\n\".format(np.shape(ListContainingWeithsTensor[i])))\n",
    "    return None\n",
    "\n",
    "#GetTensorWeithsData(ListContainingWeithsTensor)\n",
    "                \n",
    "# Initial Weights / Initial Input Trajectory\n",
    "uu = ListContainingWeithsTensor# uu is the tensor containing all the waiths of the neural network ???\n",
    "\n",
    "# Initial State Trajectory\n",
    "xx = forward_pass(uu,data_point[0], NNShape) # T x d . we pass once the data to the to our neural network\n",
    "\n",
    "# GO!\n",
    "for k in range(max_iters):\n",
    "  if k%10 == 0:\n",
    "    print('Cost at k={:d} is {:.4f}'.format(k,J[k-1]))\n",
    "\n",
    "  # Backward propagation\n",
    "  llambdaT = 2*( xx[-1] - label_point[0]) # xT . LambdaT = 2*(-LablePoint)\n",
    "  Delta_u = backward_pass(xx,uu,llambdaT) # the gradient of the loss function \n",
    "  \n",
    "  # Update the weights\n",
    "  uu = uu - stepsize*Delta_u # overwriting the old value\n",
    "  \n",
    "  # Forward propagation\n",
    "  xx = forward_pass(uu, data_point[0], NNShape)# <------------------------------------------------------ OK\n",
    "  \n",
    "  # Store the Loss Value across Iterations\n",
    "  # here he compute the squere of the error, (value of the last node minus the lable)^2\n",
    "  # xx[-1] is the last value of the node of the neural network\n",
    "  J[k] = (xx[-1] - label_point[0])@(xx[-1] - label_point[0]) # it is the cost at k+1. <----------------- OK\n",
    "  # np.linalg.norm( xx[-1,:] - label_point[0] )**2\n",
    "\n",
    "_,ax = plt.subplots()\n",
    "ax.plot(range(max_iters),J)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad1c50",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(xx))\n",
    "#plt.matshow(np.reshape(xx[0], (28, 28)))\n",
    "#plt.matshow(np.reshape(xx[1], (np.shape(xx[1])/2, 2)))\n",
    "#plt.show()\n",
    "print(xx[4])\n",
    "print(xx[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc43ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xt = np.array([0.77687937, 0.08063935, 0.01138057, 0.122775, 0.45234997, 0.31188696, 0.90724203, 0.56045335, 0.77011777, 0.47297238])\n",
    "ut = np.array([3.5497876, 0.80632542, 0.42563381, 1.14425937, -0.30383338, -1.75322509, 0.22340017, -0.55091153, 0.57918906, -1.25920521])\n",
    "resoult = xt@ut\n",
    "resoult = sigmoid_fn(resoult)\n",
    "print(resoult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd82cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10362dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6972fcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cb165",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536e9e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54b9bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dde5a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(x_train[99])# i wanted to see the 100 image \n",
    "plt.colorbar()# i want to have the gradueted bar with colors\n",
    "plt.grid(False)# i dont want to have a grid on the image\n",
    "plt.xlabel(y_train[99])# write the number on the photo on x axis\n",
    "plt.show()# show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a9f9b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255# used for scaling of the numbers rappresenting the color of the image\n",
    "# its a good practice becouse otherwise we will operete with very large numbers and this will\n",
    "# give us problems ( overflow )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ed547",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# same thing as above ( just to see if the conversion were done correctly )\n",
    "plt.matshow(x_train[99])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.xlabel(y_train[99])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8e6f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# display the first 25 training images with labels and verify that the data is in the correct formate.\n",
    "plt.figure(figsize=(10,10))# <--------------------------------------------------------------------------- UNKNOWN\n",
    "for i in range(25):# i want to plot 25 images\n",
    "    plt.subplot(5,5,i+1)# the letter \"i\" rappresent the position \n",
    "    plt.xticks([])# <------------------------------------------------------------------------------------ UNKNOWN\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)# in this way i will not have the grid in on the images\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)# load the image and make it show black and white\n",
    "    plt.xlabel(y_train[i])# add the lable associated to that image under it\n",
    "plt.show()# show all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e406d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creation of the structure of neural network\n",
    "# (i dont know which activation function is the best for this problem same for the inner and last layer dimensions)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), # this layer will convert two dimetional (2d) array (image of 28x28 pixels) in to a one dimentional array of 28*28 = 784pixels.\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)# last layer has 10 neurons, with softmax as activation function\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06849e09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration of neural network \n",
    "model.compile(optimizer='adam',# we have seen it duering the lessosn\n",
    "             loss='sparse_categorical_crossentropy',# <---------------------------------------------------- UNKNOWN\n",
    "             metrics=['accuracy'])# <---------------------------------------------------------------------- UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90907093",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "#ann_viz(model, title=\"My first neural network\")\n",
    "\n",
    "#visualizer(model, format='png', view=True)# this give us an error\n",
    "#plot_model(model, to_file='model.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad477e92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training of the model \n",
    "model.fit(x_train, y_train, epochs=1)# we do the training for only one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8bfcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)# test the model on our test set\n",
    "print('test accuracy:{0}\\ntest loss:{1}'.format(test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1deee89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for layer in model.layers: print(layer.get_config(), layer.get_weights())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c7e06",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number of layers: {0}\".format(len(layer.get_weights())))\n",
    "print(\"First layer shape: {0}\".format(np.shape(layer.get_weights()[0])))\n",
    "#print(\"Second layer shape: {0}\".format(np.shape(layer.get_weights()[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff0848",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction for single images\n",
    "\n",
    "# we know that y_test[kk] image is something, we want to see if our neural networck predict it correctly\n",
    "kk = 9# image number in the training set thet we want to check\n",
    "img = x_test[kk]\n",
    "# print(img.shape)  # shape (28, 28)\n",
    "\n",
    "# tf.keras model are optimized to make predictions for batch or collection of test data at once. So we need to add it to a list:\n",
    "img_list = np.expand_dims(img,0)\n",
    "# print(img_list)   # shape (1, 28, 28)\n",
    "\n",
    "predictions_single = model.predict(img_list)# performe the prediction\n",
    "\n",
    "plt.matshow(x_test[kk])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.xlabel(\"The lable is: {0}\\nwhile the predicted value is:{1}\".format(y_test[kk], np.argmax(predictions_single)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d10dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89671bd1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804ee67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f27aba7de901f0b43cdce99199f8eab57e9e4bade0b8eaa2447270c05eeb2dce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}