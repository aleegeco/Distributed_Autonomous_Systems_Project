{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24fa964",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#  WARNING, EXECUTE THIS LINE BEFORE EXEsCUTING ANY ROS CODE #\n",
    "#                                                            #\n",
    "#             source opt/ros/foxy/setup.bash                 #\n",
    "#                                                            #\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ede3818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 15:40:33.073060: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-24 15:40:33.073112: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function# need to undestend their utility <-------- UNKNOWN\n",
    "import tensorflow as tf\n",
    "import keras# dont import keras ftom tensorflow library otherwise the code below will fail\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras_visualizer import visualizer# used to visualize the neural network <-------------------- MORE INFORMATION\n",
    "from tensorflow.keras.utils import plot_model# used to plot the neural network model <------------------MORE INFO\n",
    "import matplotlib.pyplot as plt# this library will be used for data visualization\n",
    "\n",
    "TestSize = 1# size of the test set\n",
    "\n",
    "percent = 0.2# percentage of data we want to give to our system from all the data aveilable\n",
    "# we start to take them from the start of the dataset , one after one)\n",
    "\n",
    "LukyNumber = 4# the number that in this session will be associated to 1 while the others will be set to 0\n",
    "# (we set all the other numbers to zero becouse otherwise the neural network behave incorrectly with thos libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060d4704",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# import the dataset \"mnist\" that contains all the images of the numbers\n",
    "# and relatives lables an then assine all those data to two sets ( training set and test set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248c7c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "60000\n",
      "(60000, 28, 28)\n",
      "<class 'numpy.ndarray'>\n",
      "10000\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# I want to see some information about my data and they format\n",
    "print(type(x_train))# return the typology of our data set of images\n",
    "print(len(x_train))# retunr the lenth of the data set ( how much images we have )\n",
    "print(np.shape(x_train))# return the shape of the data set, in our case we have the\n",
    "# lenth and then the dimensions of the images\n",
    "\n",
    "print(type(x_test))# return the typology of our training set of images\n",
    "print(len(x_test))# retunr the lenth of the training set ( how much images we have )\n",
    "print(np.shape(x_test))# return the shape of the training set, in our case we have the\n",
    "# lenth and then the dimensions of the images\n",
    "\n",
    "#print(dir(np))\n",
    "#print(help(np.concatenate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ee9fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_total_temp: (70000, 28, 28)\n",
      "Shape of x_total reduced to 0.2: (14000, 28, 28)\n",
      "Shape of y_total_temp: (70000,)\n",
      "Shape of y_total reduced to 0.2: (14000,)\n"
     ]
    }
   ],
   "source": [
    "'''                             I HAVE TO CHECK IF THIS PART OF THE CODE IS CORRECT                            '''\n",
    "\n",
    "#                                    Reduction of the dataset dimension\n",
    "\n",
    "x_total_temp = np.append(x_train, x_test, axis=0)# CHECK IF THE PARTS ARE APPENDED CORRECTLY <------------- WARNING\n",
    "print(\"Shape of x_total_temp: {0}\".format(np.shape(x_total_temp)))\n",
    "\n",
    "x_total = x_total_temp[0: int(np.shape(x_total_temp)[0]*percent)]\n",
    "print(\"Shape of x_total reduced to {1}: {0}\".format(np.shape(x_total), percent))\n",
    "\n",
    "y_total_temp = np.append(y_train, y_test, axis=0)# CHECK IF THE PARTS ARE APPENDED CORRECTLY <------------- WARNING\n",
    "print(\"Shape of y_total_temp: {0}\".format(np.shape(y_total_temp)))\n",
    "\n",
    "y_total = y_total_temp[0: int(np.shape(y_total_temp)[0]*percent)]\n",
    "print(\"Shape of y_total reduced to {1}: {0}\".format(np.shape(y_total), percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429bfe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"                                       THE ERROR COULD BE HERE                                                \"\"\"\n",
    "# Redistribution of the data in two sets ( test and train)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_total, y_total, test_size=TestSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672f5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"                                       THE ERROR COULD BE HERE                                                \"\"\"\n",
    "#                                     Assignment of values [1, 0]\n",
    "\n",
    "# REWRITE THE CODE BECAUSE IT ISNT EFFISCENT ENOUGH (nested for loops or something else)\n",
    "\n",
    "for i in range(0, np.shape(y_train)[0]):# <-------------------------------------------------- WARNING (use iterator)\n",
    "    if y_train[i] == LukyNumber:\n",
    "        pass\n",
    "    else:\n",
    "        y_train[i] = 0\n",
    "        \n",
    "for i in range(0, np.shape(y_test)[0]):# <-------------------------------------------------- WARNING (use iterator)\n",
    "    if y_test[i] == LukyNumber:\n",
    "        pass\n",
    "    else:\n",
    "        y_test[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db5d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth of y_training : 13999\n",
      "\n",
      "Shape of y_training : (13999,)\n",
      "\n",
      "y_training : [0 0 0 ... 0 0 0]\n",
      "\n",
      "Lenth of x_training : 13999\n",
      "\n",
      "Shape of x_training : (13999, 28, 28)\n",
      "\n",
      "x_training : [[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST TO SEE THE SHAPE OF THE DATA\n",
    "print(\"Lenth of y_training : {}\\n\".format(len(y_train)))\n",
    "print(\"Shape of y_training : {}\\n\".format(np.shape(y_train)))\n",
    "print(\"y_training : {}\\n\".format(y_train))\n",
    "\n",
    "# I WANT TO SEE THE SHAPE OF PICTURES\n",
    "print(\"Lenth of x_training : {}\\n\".format(len(x_train)))\n",
    "print(\"Shape of x_training : {}\\n\".format(np.shape(x_train)))\n",
    "print(\"x_training : {}\\n\".format(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c7f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth of y_training : 13999\n",
      "\n",
      "Shape of y_training : (13999,)\n",
      "\n",
      "y_training : [0 0 0 ... 0 0 0]\n",
      "\n",
      "Lenth of x_training : 13999\n",
      "\n",
      "Shape of x_training : (13999, 784)\n",
      "\n",
      "x_training : [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HERE I RESHAPE THE IMAGES FROM A MATRIX TO A VECTOR MANTAINING THE DATA CONTENT\n",
    "SrecchedDatasetX = np.reshape(x_train, (np.shape(x_train)[0], 784))# the dataset has 11200 elements, you have to make this part of code more general\n",
    "\n",
    "# TEST TO SEE THE SHAPE OF THE DATA\n",
    "print(\"Lenth of y_training : {}\\n\".format(len(y_train)))\n",
    "print(\"Shape of y_training : {}\\n\".format(np.shape(y_train)))\n",
    "print(\"y_training : {}\\n\".format(y_train))\n",
    "\n",
    "# I WANT TO SEE THE SHAPE OF PICTURES\n",
    "print(\"Lenth of x_training : {}\\n\".format(len(SrecchedDatasetX)))\n",
    "print(\"Shape of x_training : {}\\n\".format(np.shape(SrecchedDatasetX)))\n",
    "print(\"x_training : {}\\n\".format(SrecchedDatasetX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acb9839b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HERE I TEST THE CONVERSION GOING BACKWARD (CHEKING IF THE IMAGE IS CORRECT)\n",
    "#print(SrecchedDatasetX[1])\n",
    "prova = np.reshape(SrecchedDatasetX[int(371)], (28, 28))# here at index you can put whatewer number you wish to see if the conversion went correctly\n",
    "plt.matshow(prova)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472451d",
   "metadata": {},
   "source": [
    "The erlier part was a preprocessing of the data, now we will use distributed gradient traking for the training of the neural network.\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90f9929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape of a: (784, 10, 10, 10, 1)\n",
      "\n",
      "aa: [[ 1.33798865 -1.6605827  -0.57216696]\n",
      " [ 1.1289137   0.77496828 -1.14373259]]\n",
      "\n",
      "bb: [[ 0.33547355 -1.18281509]\n",
      " [ 0.51027498  0.09207799]\n",
      " [ 1.06621992  0.57219764]]\n",
      "uu_test: [array([[ 1.33798865, -1.6605827 , -0.57216696],\n",
      "       [ 1.1289137 ,  0.77496828, -1.14373259]]), array([[ 0.33547355, -1.18281509],\n",
      "       [ 0.51027498,  0.09207799],\n",
      "       [ 1.06621992,  0.57219764]])]\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "def adder(a: float, b: float) -> float:\n",
    "    return float(a+b)\n",
    "#type(adder(3, 5))\n",
    "\n",
    "NNShape = np.array([784, 10, 10, 10, 1])\n",
    "a = np.zeros(tuple(NNShape))\n",
    "print(\"\\nshape of a: {0}\".format(np.shape(a)))\n",
    "#print(a)\n",
    "#a[0]=np.array([1, 2, 3, 4])\n",
    "#print(a)\n",
    "\n",
    "#chiodo = np.zeros([])\n",
    "#print(np.shape(chiodo))\n",
    "#uu_test = np.random.randn(3, 3)\n",
    "aa = np.random.randn(2, 3)\n",
    "bb = np.random.randn(3, 2)\n",
    "uu_test = list()\n",
    "uu_test.append(aa)\n",
    "uu_test.append(bb)\n",
    "#uu_test = np.append(uu_test, np.random.randn(2, 2), axis=0)\n",
    "#uu_test = np.array(aa, bb)\n",
    "\n",
    "print(\"\\naa: {0}\".format(aa))\n",
    "print(\"\\nbb: {0}\".format(bb))\n",
    "print(\"uu_test: {0}\".format(uu_test))\n",
    "#plt.matshow(uu_test)\n",
    "#plt.show()\n",
    "\n",
    "#T = 4\n",
    "#d = 10\n",
    "#uu = np.random.randn(T-1, d, d+1)\n",
    "#print(np.shape(uu))\n",
    "#print(uu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e5fa1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3143909646.py, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [14]\u001b[0;36m\u001b[0m\n\u001b[0;31m    xx[0] = x0# this is the first layer of the neural network. It has to bee the image (vector rappresenting the image)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# https://ojs.aaai.org/index.php/AAAI/article/download/7178/7032\n",
    "###############################################################################\n",
    "\n",
    "# this array rappresents the shape of our neural network\n",
    "# each i-th element of the array says how much neurons has that layer\n",
    "# the first layer has 784 neurons becouse is the layer rappresenting the vectorazed image\n",
    "# the last layer is composed by one neuron becouse it will say if the image contains the LukyNumber or not\n",
    "NNShape = np.array([784, 10, 10, 10, 1])\n",
    "\n",
    "# Training Set\n",
    "label_point = y_train # D = x0\n",
    "data_point = SrecchedDatasetX # y = xT = phi (ustar)\n",
    "\n",
    "# Gradient Method Parameters\n",
    "max_iters = 10 # epochs\n",
    "stepsize = 0.1 # learning rate\n",
    "\n",
    "###############################################################################\n",
    "# Activation Function\n",
    "def sigmoid_fn(xi: float) -> float:\n",
    "  return 1/(1+np.exp(-xi))\n",
    "\n",
    "# Derivative of Activation Function\n",
    "def sigmoid_fn_derivative(xi: float) -> float:\n",
    "  return sigmoid_fn(xi)*(1-sigmoid_fn(xi))\n",
    "\n",
    "# Calculate the output of one layer of neurons given the input of previous layer and the weiths\n",
    "def inference_dynamics(xt: np.array, ut: np.array, d: np.array, WhereIAm: int) -> np.array:\n",
    "  \"\"\"\n",
    "    input: \n",
    "              xt -> previous layer resoults\n",
    "              ut -> current layer weiths\n",
    "              d  -> array containing the number of nodes of each layer\n",
    "              WhereIAm -> integer that says which layer you have selected now\n",
    "    output: \n",
    "              xtp -> output of this layer\n",
    "  \"\"\"\n",
    "  # allocate space for the output ( input of the next layer )\n",
    "  xtp = np.zeros(d[WhereIAm+1])# here i am looking for the number of neurons of the next layer\n",
    "  for ell in range(d[WhereIAm]):# for each node of this layer compute those operations\n",
    "    temp = xt@ut[ell,1:] + ut[ell,0] # calculate the output of the neuron including the bias\n",
    "    xtp[ell] = sigmoid_fn(temp) # x' * u_ell. . Calculate the output of one neuron and put it in the next layer\n",
    "  return xtp\n",
    "\n",
    "# Calculation of layers of neurons output for each layer untill the end\n",
    "def forward_pass(uu: np.array, x0: np.array, d: np.array) -> np.array:\n",
    "  \"\"\"\n",
    "    input: \n",
    "              uu -> tensor containing all the weiths of the neural network\n",
    "              x0 -> input of neural network (in this case the vectorized image)\n",
    "              d -> array containing the number of nodes of each layer\n",
    "    output: \n",
    "              xx -> output of our neurla network\n",
    "  \"\"\"\n",
    "  # allocate the memory for the resoults of the whole neural network.\n",
    "  xx = np.zeros(tuple(NNShape)# here i create a tensor of shape [784, 10, 10, 10, 1] containing only zeros\n",
    "        \n",
    "  xx[0] = x0# this is the first layer of the neural network. It has to bee the image (vector rappresenting the image)\n",
    "\n",
    "  for t in range(T-1):\n",
    "    # calculate the resoults of the computation of the whole neural network\n",
    "    xx[t+1] = inference_dynamics(xx[t],uu[t], d, t)# i put t becouse we skip the firs layer ?\n",
    "  return xx\n",
    "  \n",
    "\n",
    "'''\n",
    "# Adjoint dynamics: \n",
    "#   state:    lambda_t = A.T lambda_tp\n",
    "#   output: deltau_t = B.T lambda_tp\n",
    "def adjoint_dynamics(ltp,xt,ut):\n",
    "  \"\"\"\n",
    "    input: \n",
    "              llambda_tp current costate\n",
    "              xt current state\n",
    "              ut current input\n",
    "    output: \n",
    "              llambda_t next costate\n",
    "              delta_ut loss gradient wrt u_t\n",
    "  \"\"\"\n",
    "  df_dx = np.zeros((d,d))\n",
    "\n",
    "  # df_du = np.zeros((d,(d+1)*d))\n",
    "  Delta_ut = np.zeros((d,d+1))\n",
    "\n",
    "  for j in range(d):\n",
    "    dsigma_j = sigmoid_fn_derivative(xt@ut[j,1:] + ut[j,0]) \n",
    "\n",
    "    df_dx[:,j] = ut[j,1:]*dsigma_j\n",
    "    # df_du[j, XX] = dsigma_j*np.hstack([1,xt])\n",
    "    \n",
    "    # B'@ltp\n",
    "    Delta_ut[j,0] = ltp[j]*dsigma_j\n",
    "    Delta_ut[j,1:] = xt*ltp[j]*dsigma_j\n",
    "  \n",
    "  lt = df_dx@ltp # A'@ltp\n",
    "  # Delta_ut = df_du@ltp\n",
    "\n",
    "  return lt, Delta_ut\n",
    "\n",
    "# Backward Propagation\n",
    "def backward_pass(xx,uu,llambdaT):\n",
    "  \"\"\"\n",
    "    input: \n",
    "              xx state trajectory: x[1],x[2],..., x[T]\n",
    "              uu input trajectory: u[0],u[1],..., u[T-1]\n",
    "              llambdaT terminal condition\n",
    "    output: \n",
    "              llambda costate trajectory\n",
    "              delta_u costate output, i.e., the loss gradient\n",
    "  \"\"\"\n",
    "  llambda = np.zeros((T,d))\n",
    "  llambda[-1] = llambdaT\n",
    "\n",
    "  Delta_u = np.zeros((T-1,d,d+1))\n",
    "\n",
    "  for t in reversed(range(T-1)): # T-2,T-1,...,1,0\n",
    "    llambda[t], Delta_u[t] = adjoint_dynamics(llambda[t+1],xx[t],uu[t])\n",
    "\n",
    "  return Delta_u\n",
    "'''\n",
    "  \n",
    "###############################################################################\n",
    "# MAIN\n",
    "###############################################################################\n",
    "\n",
    "J = np.zeros(max_iters)                       # Vector containing the evolution of the cost\n",
    "\n",
    "# Initial Weights / Initial Input Trajectory\n",
    "uu = np.random.randn(T-1, d, d+1)# uu is the tensor containing all the waiths of the neural network ???\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Initial State Trajectory\n",
    "xx = forward_pass(uu,data_point[0]) # T x d . we pass once the data to the to our neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "# GO!\n",
    "for k in range(max_iters):\n",
    "  if k%10 == 0:\n",
    "    print('Cost at k={:d} is {:.4f}'.format(k,J[k-1]))\n",
    "\n",
    "  # Backward propagation\n",
    "  llambdaT = 2*( xx[-1,:] - label_point) # xT\n",
    "  Delta_u = backward_pass(xx,uu,llambdaT) # the gradient of the loss function \n",
    "  \n",
    "  # Update the weights\n",
    "  uu = uu - stepsize*Delta_u # overwriting the old value\n",
    "  \n",
    "  # Forward propagation\n",
    "  xx = forward_pass(uu,data_point)\n",
    "  \n",
    "  # Store the Loss Value across Iterations\n",
    "  J[k] = (xx[-1,:] - label_point)@(xx[-1,:] - label_point) # it is the cost at k+1\n",
    "  # np.linalg.norm( xx[-1,:] - label_point )**2\n",
    "\n",
    "_,ax = plt.subplots()\n",
    "ax.plot(range(max_iters),J)\n",
    "plt.show()\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10362dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6972fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cb165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536e9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54b9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dde5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(x_train[99])# i wanted to see the 100 image \n",
    "plt.colorbar()# i want to have the gradueted bar with colors\n",
    "plt.grid(False)# i dont want to have a grid on the image\n",
    "plt.xlabel(y_train[99])# write the number on the photo on x axis\n",
    "plt.show()# show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255# used for scaling of the numbers rappresenting the color of the image\n",
    "# its a good practice becouse otherwise we will operete with very large numbers and this will\n",
    "# give us problems ( overflow )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ed547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing as above ( just to see if the conversion were done correctly )\n",
    "plt.matshow(x_train[99])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.xlabel(y_train[99])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 25 training images with labels and verify that the data is in the correct formate.\n",
    "plt.figure(figsize=(10,10))# <--------------------------------------------------------------------------- UNKNOWN\n",
    "for i in range(25):# i want to plot 25 images\n",
    "    plt.subplot(5,5,i+1)# the letter \"i\" rappresent the position \n",
    "    plt.xticks([])# <------------------------------------------------------------------------------------ UNKNOWN\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)# in this way i will not have the grid in on the images\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)# load the image and make it show black and white\n",
    "    plt.xlabel(y_train[i])# add the lable associated to that image under it\n",
    "plt.show()# show all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the structure of neural network\n",
    "# (i dont know which activation function is the best for this problem same for the inner and last layer dimensions)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), # this layer will convert two dimetional (2d) array (image of 28x28 pixels) in to a one dimentional array of 28*28 = 784pixels.\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)# last layer has 10 neurons, with softmax as activation function\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06849e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of neural network \n",
    "model.compile(optimizer='adam',# we have seen it duering the lessosn\n",
    "             loss='sparse_categorical_crossentropy',# <---------------------------------------------------- UNKNOWN\n",
    "             metrics=['accuracy'])# <---------------------------------------------------------------------- UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90907093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "#ann_viz(model, title=\"My first neural network\")\n",
    "\n",
    "#visualizer(model, format='png', view=True)# this give us an error\n",
    "#plot_model(model, to_file='model.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad477e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of the model \n",
    "model.fit(x_train, y_train, epochs=1)# we do the training for only one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)# test the model on our test set\n",
    "print('test accuracy:{0}\\ntest loss:{1}'.format(test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1deee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in model.layers: print(layer.get_config(), layer.get_weights())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number of layers: {0}\".format(len(layer.get_weights())))\n",
    "print(\"First layer shape: {0}\".format(np.shape(layer.get_weights()[0])))\n",
    "#print(\"Second layer shape: {0}\".format(np.shape(layer.get_weights()[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for single images\n",
    "\n",
    "# we know that y_test[kk] image is something, we want to see if our neural networck predict it correctly\n",
    "kk = 9# image number in the training set thet we want to check\n",
    "img = x_test[kk]\n",
    "# print(img.shape)  # shape (28, 28)\n",
    "\n",
    "# tf.keras model are optimized to make predictions for batch or collection of test data at once. So we need to add it to a list:\n",
    "img_list = np.expand_dims(img,0)\n",
    "# print(img_list)   # shape (1, 28, 28)\n",
    "\n",
    "predictions_single = model.predict(img_list)# performe the prediction\n",
    "\n",
    "plt.matshow(x_test[kk])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.xlabel(\"The lable is: {0}\\nwhile the predicted value is:{1}\".format(y_test[kk], np.argmax(predictions_single)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d10dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89671bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804ee67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f27aba7de901f0b43cdce99199f8eab57e9e4bade0b8eaa2447270c05eeb2dce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
