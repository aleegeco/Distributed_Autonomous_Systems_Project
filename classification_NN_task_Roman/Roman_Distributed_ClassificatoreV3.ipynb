{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24fa964",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#  WARNING, EXECUTE THIS LINE BEFORE EXEsCUTING ANY ROS CODE #\n",
    "#                                                            #\n",
    "#             source opt/ros/foxy/setup.bash                 #\n",
    "#                                                            #\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ede3818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 19:05:50.528361: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-24 19:05:50.528403: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function# need to undestend their utility <-------- UNKNOWN\n",
    "import tensorflow as tf\n",
    "import keras# dont import keras ftom tensorflow library otherwise the code below will fail\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras_visualizer import visualizer# used to visualize the neural network <-------------------- MORE INFORMATION\n",
    "from tensorflow.keras.utils import plot_model# used to plot the neural network model <------------------MORE INFO\n",
    "import matplotlib.pyplot as plt# this library will be used for data visualization\n",
    "\n",
    "TestSize = 1# size of the test set\n",
    "\n",
    "percent = 0.2# percentage of data we want to give to our system from all the data aveilable\n",
    "# we start to take them from the start of the dataset , one after one)\n",
    "\n",
    "LukyNumber = 4# the number that in this session will be associated to 1 while the others will be set to 0\n",
    "# (we set all the other numbers to zero becouse otherwise the neural network behave incorrectly with thos libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060d4704",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# import the dataset \"mnist\" that contains all the images of the numbers\n",
    "# and relatives lables an then assine all those data to two sets ( training set and test set )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248c7c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "60000\n",
      "(60000, 28, 28)\n",
      "<class 'numpy.ndarray'>\n",
      "10000\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# I want to see some information about my data and they format\n",
    "print(type(x_train))# return the typology of our data set of images\n",
    "print(len(x_train))# retunr the lenth of the data set ( how much images we have )\n",
    "print(np.shape(x_train))# return the shape of the data set, in our case we have the\n",
    "# lenth and then the dimensions of the images\n",
    "\n",
    "print(type(x_test))# return the typology of our training set of images\n",
    "print(len(x_test))# retunr the lenth of the training set ( how much images we have )\n",
    "print(np.shape(x_test))# return the shape of the training set, in our case we have the\n",
    "# lenth and then the dimensions of the images\n",
    "\n",
    "#print(dir(np))\n",
    "#print(help(np.concatenate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ee9fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_total_temp: (70000, 28, 28)\n",
      "Shape of x_total reduced to 0.2: (14000, 28, 28)\n",
      "Shape of y_total_temp: (70000,)\n",
      "Shape of y_total reduced to 0.2: (14000,)\n"
     ]
    }
   ],
   "source": [
    "'''                             I HAVE TO CHECK IF THIS PART OF THE CODE IS CORRECT                            '''\n",
    "\n",
    "#                                    Reduction of the dataset dimension\n",
    "\n",
    "x_total_temp = np.append(x_train, x_test, axis=0)# CHECK IF THE PARTS ARE APPENDED CORRECTLY <------------- WARNING\n",
    "print(\"Shape of x_total_temp: {0}\".format(np.shape(x_total_temp)))\n",
    "\n",
    "x_total = x_total_temp[0: int(np.shape(x_total_temp)[0]*percent)]\n",
    "print(\"Shape of x_total reduced to {1}: {0}\".format(np.shape(x_total), percent))\n",
    "\n",
    "y_total_temp = np.append(y_train, y_test, axis=0)# CHECK IF THE PARTS ARE APPENDED CORRECTLY <------------- WARNING\n",
    "print(\"Shape of y_total_temp: {0}\".format(np.shape(y_total_temp)))\n",
    "\n",
    "y_total = y_total_temp[0: int(np.shape(y_total_temp)[0]*percent)]\n",
    "print(\"Shape of y_total reduced to {1}: {0}\".format(np.shape(y_total), percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429bfe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"                                       THE ERROR COULD BE HERE                                                \"\"\"\n",
    "# Redistribution of the data in two sets ( test and train)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_total, y_total, test_size=TestSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672f5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"                                       THE ERROR COULD BE HERE                                                \"\"\"\n",
    "#                                     Assignment of values [1, 0]\n",
    "\n",
    "# REWRITE THE CODE BECAUSE IT ISNT EFFISCENT ENOUGH (nested for loops or something else)\n",
    "\n",
    "for i in range(0, np.shape(y_train)[0]):# <-------------------------------------------------- WARNING (use iterator)\n",
    "    if y_train[i] == LukyNumber:\n",
    "        pass\n",
    "    else:\n",
    "        y_train[i] = 0\n",
    "        \n",
    "for i in range(0, np.shape(y_test)[0]):# <-------------------------------------------------- WARNING (use iterator)\n",
    "    if y_test[i] == LukyNumber:\n",
    "        pass\n",
    "    else:\n",
    "        y_test[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db5d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth of y_training : 13999\n",
      "\n",
      "Shape of y_training : (13999,)\n",
      "\n",
      "y_training : [0 0 0 ... 0 0 0]\n",
      "\n",
      "Lenth of x_training : 13999\n",
      "\n",
      "Shape of x_training : (13999, 28, 28)\n",
      "\n",
      "x_training : [[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST TO SEE THE SHAPE OF THE DATA\n",
    "print(\"Lenth of y_training : {}\\n\".format(len(y_train)))\n",
    "print(\"Shape of y_training : {}\\n\".format(np.shape(y_train)))\n",
    "print(\"y_training : {}\\n\".format(y_train))\n",
    "\n",
    "# I WANT TO SEE THE SHAPE OF PICTURES\n",
    "print(\"Lenth of x_training : {}\\n\".format(len(x_train)))\n",
    "print(\"Shape of x_training : {}\\n\".format(np.shape(x_train)))\n",
    "print(\"x_training : {}\\n\".format(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c7f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenth of y_training : 13999\n",
      "\n",
      "Shape of y_training : (13999,)\n",
      "\n",
      "y_training : [0 0 0 ... 0 0 0]\n",
      "\n",
      "Lenth of x_training : 13999\n",
      "\n",
      "Shape of x_training : (13999, 784)\n",
      "\n",
      "x_training : [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HERE I RESHAPE THE IMAGES FROM A MATRIX TO A VECTOR MANTAINING THE DATA CONTENT\n",
    "SrecchedDatasetX = np.reshape(x_train, (np.shape(x_train)[0], 784))# the dataset has 11200 elements, you have to make this part of code more general\n",
    "\n",
    "# TEST TO SEE THE SHAPE OF THE DATA\n",
    "print(\"Lenth of y_training : {}\\n\".format(len(y_train)))\n",
    "print(\"Shape of y_training : {}\\n\".format(np.shape(y_train)))\n",
    "print(\"y_training : {}\\n\".format(y_train))\n",
    "\n",
    "# I WANT TO SEE THE SHAPE OF PICTURES\n",
    "print(\"Lenth of x_training : {}\\n\".format(len(SrecchedDatasetX)))\n",
    "print(\"Shape of x_training : {}\\n\".format(np.shape(SrecchedDatasetX)))\n",
    "print(\"x_training : {}\\n\".format(SrecchedDatasetX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb9839b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# HERE I TEST THE CONVERSION GOING BACKWARD (CHEKING IF THE IMAGE IS CORRECT)\n",
    "#print(SrecchedDatasetX[1])\n",
    "prova = np.reshape(SrecchedDatasetX[int(371)], (28, 28))# here at index you can put whatewer number you wish to see if the conversion went correctly\n",
    "plt.matshow(prova)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7472451d",
   "metadata": {},
   "source": [
    "The erlier part was a preprocessing of the data, now we will use distributed gradient traking for the training of the neural network.\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90f9929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example \n",
    "def adder(a: float, b: float) -> float:\n",
    "    return float(a+b)\n",
    "#type(adder(3, 5))\n",
    "\n",
    "#NNShape = np.array([784, 10, 10, 10, 1])\n",
    "#a = np.zeros(tuple(NNShape))\n",
    "#print(\"\\nshape of a: {0}\".format(np.shape(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e5fa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhereIAm: 0\n",
      "\n",
      "shape of xtp: (10,)\n",
      "\n",
      "shape of d[WhereIAm]: (5,)\n",
      "\n",
      "shape of xt: (784,)\n",
      "\n",
      "shape of ut: (10, 784)\n",
      "\n",
      "xtp: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "d[WhereIAm]: 784\n",
      "\n",
      "xt: [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  24 193  66\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0  10 186 254 172   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  21 188 254\n",
      " 254 103   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 178 254 254 234   6   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 215\n",
      " 254 254  98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 215 254 242  79   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 215 254 188   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 113 251 254 145   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  21 204 254 254  24   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0  87 254 254 254  24   0  81\n",
      "  83  83  75   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 198 254 254 254 181 173 252 254 254 247 173 145   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 198 254 254 254 254\n",
      " 254 254 254 254 254 254 229  48   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0 198 254 254 254 232 230 230 230 230 230 241 255 221\n",
      "  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0 198 254 254\n",
      " 191  13   0   0   0   0   0  64 233 254  32   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 198 254 254 115   0   0   0   0   0   0  19\n",
      " 214 233  27   0   0   0   0   0   0   0   0   0   0   0   0   0   0 198\n",
      " 254 254 187  13   0   0   0   0  13 188 233  59   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0 161 254 254 254  76  23   0   2  58\n",
      " 184 254 213   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14 178 254 254 254 189 149 152 254 254 254 117   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   8 217 254 254 254 254\n",
      " 254 254 247 106   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  76 180 254 254 254 249  90  81   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "ut: [[-1.50587504  0.80201642 -1.52919856 ... -0.73451941  0.37375804\n",
      "  -0.60247362]\n",
      " [ 1.40996972  0.85926575 -0.00343048 ...  0.48057052  0.48810746\n",
      "  -0.83094391]\n",
      " [-0.39678371 -1.75610051 -1.29977597 ...  0.68619255 -0.18259992\n",
      "   0.97633933]\n",
      " ...\n",
      " [ 0.74034262 -1.51038688  1.11037881 ...  0.78764701 -1.06397128\n",
      "  -0.06821509]\n",
      " [ 0.90163965  0.63817032  0.01787218 ... -0.72823203  0.88880358\n",
      "  -0.79477063]\n",
      " [ 0.73797966  1.15065464  0.26997224 ...  2.03442545  1.00334895\n",
      "  -1.18517564]]\n",
      "\n",
      "WhereIAm: 1\n",
      "\n",
      "shape of xtp: (10,)\n",
      "\n",
      "shape of d[WhereIAm]: (5,)\n",
      "\n",
      "shape of xt: (10,)\n",
      "\n",
      "shape of ut: (10, 10)\n",
      "\n",
      "xtp: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "d[WhereIAm]: 10\n",
      "\n",
      "xt: [1.00000000e+000 1.00000000e+000 1.00000000e+000 0.00000000e+000\n",
      " 1.00000000e+000 1.00000000e+000 0.00000000e+000 1.00000000e+000\n",
      " 1.00000000e+000 6.49423906e-141]\n",
      "\n",
      "ut: [[-0.13036414 -0.4366893  -0.13227523  0.72099766  0.39993704 -1.00792863\n",
      "  -0.41713265  2.35304139  0.20066048  0.60128327]\n",
      " [-0.11525604 -0.58743019  0.53156179 -1.21073568 -1.25391058  0.24080248\n",
      "  -1.21983028 -0.75294386  0.867893   -0.54311183]\n",
      " [-1.90185808  0.56944033 -1.40626341 -1.49743751  1.38116164 -0.51163815\n",
      "  -0.05113508 -0.43224902  1.16506814 -2.02940187]\n",
      " [-1.3878903   0.41987744 -0.86369947  1.02168392  2.68038253  0.59589203\n",
      "   1.72883512  0.7950243  -1.97826865  0.89213124]\n",
      " [ 0.69250877 -0.8733478   0.01957291  0.24664397  2.12464438  2.0516722\n",
      "  -0.40943796  1.43376013 -2.00245353  0.90623963]\n",
      " [ 0.4703956   0.33355348 -2.49166139  1.82787481  0.6458186   0.09440192\n",
      "  -0.90361011  0.43637145 -0.25738094 -0.301551  ]\n",
      " [ 0.88057633  0.94607172 -0.17185902 -1.38072182  0.49168112 -1.71525263\n",
      "  -0.86968072  0.31918155 -0.01642854 -1.72404389]\n",
      " [ 0.32317815 -0.06154176 -0.27269854 -0.90916537 -0.36145458  1.04655947\n",
      "  -2.52189427  0.38701203  0.44991182  0.11796346]\n",
      " [ 0.24058172  0.00666302  0.71440321  0.23522157  1.71915516  1.3054326\n",
      "  -1.12065059 -1.11596973  0.30628269 -0.04337363]\n",
      " [-1.85372241 -1.40516103  1.33522283 -1.10301052  0.46610256  1.28293073\n",
      "  -0.13325646 -0.30225715 -2.02508764  0.12511599]]\n",
      "\n",
      "WhereIAm: 2\n",
      "\n",
      "shape of xtp: (10,)\n",
      "\n",
      "shape of d[WhereIAm]: (5,)\n",
      "\n",
      "shape of xt: (10,)\n",
      "\n",
      "shape of ut: (10, 10)\n",
      "\n",
      "xtp: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "d[WhereIAm]: 10\n",
      "\n",
      "xt: [0.77667287 0.25553939 0.24299324 0.56496023 0.96912231 0.3168034\n",
      " 0.67567597 0.81920441 0.95994216 0.07572004]\n",
      "\n",
      "ut: [[-0.4626708   0.08306883  0.2145085  -0.29503467 -0.83952701  0.4867883\n",
      "   0.98735102  1.20292763 -0.25388722 -0.83491535]\n",
      " [ 1.34909045 -0.74939354  0.40482326  1.35417613 -0.71745407 -0.87727249\n",
      "  -0.61337021  0.00686039 -1.45925609  0.62633048]\n",
      " [-0.7668785  -0.48104453  0.88500524 -1.91096173  0.29845675 -0.23641958\n",
      "   1.00796421 -1.46617133  0.17884323  0.02358115]\n",
      " [-0.57149853  0.75146694 -0.65063269  1.18856387 -0.02453235 -0.84485752\n",
      "  -0.65942547 -1.27556229 -0.06776823  1.65795996]\n",
      " [ 1.54681435 -1.84799593 -1.21839648 -1.00915768 -0.86969387 -0.28202256\n",
      "   0.18383485  0.66058766  0.51799322 -1.9668966 ]\n",
      " [ 0.63365252  0.62699993  1.07162231  1.34576983  0.78109231 -0.44961585\n",
      "  -0.00827869  1.41441834 -0.07422558 -0.73502128]\n",
      " [-0.12039096 -1.153675   -0.01781133  0.700675   -0.70793499 -0.69499987\n",
      "   1.72418758  0.58949103 -1.23355461 -2.23643777]\n",
      " [-0.89574807  0.29196678 -0.10918067 -0.36706282 -0.96514268  0.43574761\n",
      "   0.40339769 -1.27233449  1.93458221 -0.20375212]\n",
      " [-1.0821451  -0.78561538 -2.67993805  0.19563253 -1.0434575  -1.62263982\n",
      "  -0.42352913  0.25633414  1.13440913  1.14446934]\n",
      " [-0.30132476 -0.92193833 -0.40228178 -0.5573118   0.65852382 -0.49533328\n",
      "   0.05690277 -0.53091048 -0.72850369  0.99519859]]\n",
      "\n",
      "WhereIAm: 3\n",
      "\n",
      "shape of xtp: (1,)\n",
      "\n",
      "shape of d[WhereIAm]: (5,)\n",
      "\n",
      "shape of xt: (10,)\n",
      "\n",
      "shape of ut: (1, 10)\n",
      "\n",
      "xtp: [0.]\n",
      "\n",
      "d[WhereIAm]: 10\n",
      "\n",
      "xt: [0.55812914 0.26586751 0.15247287 0.18848391 0.48611123 0.96489912\n",
      " 0.3523739  0.35884694 0.11839074 0.19444103]\n",
      "\n",
      "ut: [[-0.09087782 -1.8993562   1.3280081  -1.02377614 -0.93235763 -0.86983388\n",
      "  -1.81564591  0.85712578 -0.77465286  0.36835958]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6913/2503813173.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-xi))\n"
     ]
    }
   ],
   "source": [
    "# https://ojs.aaai.org/index.php/AAAI/article/download/7178/7032\n",
    "###############################################################################\n",
    "\n",
    "# this array rappresents the shape of our neural network\n",
    "# each i-th element of the array says how much neurons has that layer\n",
    "# the first layer has 784 neurons becouse is the layer rappresenting the vectorazed image\n",
    "# the last layer is composed by one neuron becouse it will say if the image contains the LukyNumber or not\n",
    "NNShape = np.array([784, 10, 10, 10, 1])\n",
    "\n",
    "# Training Set\n",
    "label_point = y_train # D = x0\n",
    "data_point = SrecchedDatasetX # y = xT = phi (ustar)\n",
    "\n",
    "# Gradient Method Parameters\n",
    "max_iters = 10 # epochs\n",
    "stepsize = 0.1 # learning rate\n",
    "\n",
    "###############################################################################\n",
    "# Activation Function\n",
    "def sigmoid_fn(xi: float) -> float:\n",
    "  return 1/(1+np.exp(-xi))\n",
    "\n",
    "# Derivative of Activation Function\n",
    "def sigmoid_fn_derivative(xi: float) -> float:\n",
    "  return sigmoid_fn(xi)*(1-sigmoid_fn(xi))\n",
    "\n",
    "# Calculate the output of one layer of neurons given the input of previous layer and the weiths\n",
    "def inference_dynamics(xt: np.array, ut: np.array, d: np.array, WhereIAm: int) -> np.array:\n",
    "  \"\"\"\n",
    "    input: \n",
    "              xt -> previous layer resoults\n",
    "              ut -> current layer weiths\n",
    "              d  -> array containing the number of nodes of each layer\n",
    "              WhereIAm -> integer that says which layer you have selected now\n",
    "    output: \n",
    "              xtp -> output of this layer\n",
    "  \"\"\"\n",
    "  # allocate space for the output ( input of the next layer )\n",
    "  xtp = np.zeros(d[WhereIAm+1])# here i am looking for the number of neurons of the next layer\n",
    "\n",
    "  print(\"WhereIAm: {0}\\n\".format(WhereIAm))\n",
    "  print(\"shape of xtp: {0}\\n\".format(np.shape(xtp)))\n",
    "  print(\"shape of d[WhereIAm]: {0}\\n\".format(np.shape(d)))\n",
    "  print(\"shape of xt: {0}\\n\".format(np.shape(xt)))\n",
    "  print(\"shape of ut: {0}\\n\".format(np.shape(ut)))\n",
    "\n",
    "  print(\"xtp: {0}\\n\".format(xtp))\n",
    "  print(\"d[WhereIAm]: {0}\\n\".format(d[WhereIAm]))\n",
    "  print(\"xt: {0}\\n\".format(xt))\n",
    "  print(\"ut: {0}\\n\".format(ut))\n",
    "  for ell in range(d[WhereIAm+1]):# for each node of this layer compute those operations\n",
    "    temp = xt@ut[ell,:]# calculate the output of the neuron including the bias\n",
    "    xtp[ell] = sigmoid_fn(temp) # x' * u_ell. . Calculate the output of one neuron and put it in the next layer\n",
    "  return xtp\n",
    "\n",
    "# Calculation of layers of neurons output for each layer untill the end\n",
    "def forward_pass(uu: list, x0: np.array, d: np.array) -> list:\n",
    "  \"\"\"\n",
    "    input: \n",
    "              uu -> tensor containing all the weiths of the neural network\n",
    "              x0 -> input of neural network (in this case the vectorized image)\n",
    "              d -> array containing the number of nodes of each layer\n",
    "    output: \n",
    "              xx -> output of our neurla network\n",
    "  \"\"\"\n",
    "  # allocate the memory for the resoults of the whole neural network.\n",
    "  xx = list()# here i create a tensor of shape [784, 10, 10, 10, 1] containing only zeros\n",
    "  for i in range(0, len(d)):# i start from 1 becouse in the layer zero we ahve the vectorized image\n",
    "    xx.append(np.zeros(d[i]))\n",
    "    \n",
    "  xx[0] = x0# this is the first layer of the neural network. It has to bee the image (vector rappresenting the image)\n",
    "\n",
    "  for t in range(np.shape(d)[0]-1):\n",
    "    # calculate the resoults of the computation of the whole neural network\n",
    "    xx[t+1] = inference_dynamics(xx[t],uu[t], d, t)# i put t becouse we skip the firs layer ?\n",
    "  return xx\n",
    "  \n",
    "\n",
    "'''\n",
    "# Adjoint dynamics: \n",
    "#   state:    lambda_t = A.T lambda_tp\n",
    "#   output: deltau_t = B.T lambda_tp\n",
    "def adjoint_dynamics(ltp,xt,ut):\n",
    "  \"\"\"\n",
    "    input: \n",
    "              llambda_tp current costate\n",
    "              xt current state\n",
    "              ut current input\n",
    "    output: \n",
    "              llambda_t next costate\n",
    "              delta_ut loss gradient wrt u_t\n",
    "  \"\"\"\n",
    "  df_dx = np.zeros((d,d))\n",
    "\n",
    "  # df_du = np.zeros((d,(d+1)*d))\n",
    "  Delta_ut = np.zeros((d,d+1))\n",
    "\n",
    "  for j in range(d):\n",
    "    dsigma_j = sigmoid_fn_derivative(xt@ut[j,1:] + ut[j,0]) \n",
    "\n",
    "    df_dx[:,j] = ut[j,1:]*dsigma_j\n",
    "    # df_du[j, XX] = dsigma_j*np.hstack([1,xt])\n",
    "    \n",
    "    # B'@ltp\n",
    "    Delta_ut[j,0] = ltp[j]*dsigma_j\n",
    "    Delta_ut[j,1:] = xt*ltp[j]*dsigma_j\n",
    "  \n",
    "  lt = df_dx@ltp # A'@ltp\n",
    "  # Delta_ut = df_du@ltp\n",
    "\n",
    "  return lt, Delta_ut\n",
    "\n",
    "# Backward Propagation\n",
    "def backward_pass(xx,uu,llambdaT):\n",
    "  \"\"\"\n",
    "    input: \n",
    "              xx state trajectory: x[1],x[2],..., x[T]\n",
    "              uu input trajectory: u[0],u[1],..., u[T-1]\n",
    "              llambdaT terminal condition\n",
    "    output: \n",
    "              llambda costate trajectory\n",
    "              delta_u costate output, i.e., the loss gradient\n",
    "  \"\"\"\n",
    "  llambda = np.zeros((T,d))\n",
    "  llambda[-1] = llambdaT\n",
    "\n",
    "  Delta_u = np.zeros((T-1,d,d+1))\n",
    "\n",
    "  for t in reversed(range(T-1)): # T-2,T-1,...,1,0\n",
    "    llambda[t], Delta_u[t] = adjoint_dynamics(llambda[t+1],xx[t],uu[t])\n",
    "\n",
    "  return Delta_u\n",
    "'''\n",
    "  \n",
    "###############################################################################\n",
    "# MAIN\n",
    "###############################################################################\n",
    "\n",
    "J = np.zeros(max_iters)                       # Vector containing the evolution of the cost\n",
    "\n",
    "ListContainingWeithsTensor = list()# -> it is a list containing the matrices used for inference dynamics\n",
    "for i in range(0, len(NNShape)-1):\n",
    "    ListContainingWeithsTensor.append(np.random.randn(NNShape[i+1], NNShape[i]))\n",
    "    \n",
    "def GetTensorWeithsData(ListOfMatrices: list) -> None:\n",
    "    print(\"The lenth of the List of matrices is {0}\".format(len(ListContainingWeithsTensor)))\n",
    "    print(\"It's type is: {0}\\n\".format(type(ListContainingWeithsTensor)))\n",
    "    for i in range(0, len(ListOfMatrices)):\n",
    "        print(\"The type of {0}Â° element is {1}\".format(i, type(ListContainingWeithsTensor[i])))\n",
    "        print(\"While the shape is {0}\\n\".format(np.shape(ListContainingWeithsTensor[i])))\n",
    "    return None\n",
    "\n",
    "#GetTensorWeithsData(ListContainingWeithsTensor)\n",
    "                \n",
    "# Initial Weights / Initial Input Trajectory\n",
    "uu = ListContainingWeithsTensor# uu is the tensor containing all the waiths of the neural network ???\n",
    "\n",
    "# Initial State Trajectory\n",
    "xx = forward_pass(uu,data_point[0], NNShape) # T x d . we pass once the data to the to our neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27fc43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10056097329827467\n"
     ]
    }
   ],
   "source": [
    "xt = np.array([0.55812914, 0.26586751, 0.15247287, 0.18848391, 0.48611123, 0.96489912, 0.3523739,  0.35884694, 0.11839074, 0.19444103])\n",
    "ut = np.array([-0.09087782, -1.8993562, 1.3280081, -1.02377614, -0.93235763, -0.86983388, -1.81564591, 0.85712578, -0.77465286, 0.36835958])\n",
    "resoult = xt@ut\n",
    "resoult = sigmoid_fn(resoult)\n",
    "print(resoult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "affd82cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (3618785813.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    ''''''\u001b[0m\n\u001b[0m          \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "# GO!\n",
    "for k in range(max_iters):\n",
    "  if k%10 == 0:\n",
    "    print('Cost at k={:d} is {:.4f}'.format(k,J[k-1]))\n",
    "\n",
    "  # Backward propagation\n",
    "  llambdaT = 2*( xx[-1,:] - label_point) # xT\n",
    "  Delta_u = backward_pass(xx,uu,llambdaT) # the gradient of the loss function \n",
    "  \n",
    "  # Update the weights\n",
    "  uu = uu - stepsize*Delta_u # overwriting the old value\n",
    "  \n",
    "  # Forward propagation\n",
    "  xx = forward_pass(uu,data_point)\n",
    "  \n",
    "  # Store the Loss Value across Iterations\n",
    "  J[k] = (xx[-1,:] - label_point)@(xx[-1,:] - label_point) # it is the cost at k+1\n",
    "  # np.linalg.norm( xx[-1,:] - label_point )**2\n",
    "\n",
    "_,ax = plt.subplots()\n",
    "ax.plot(range(max_iters),J)\n",
    "plt.show()\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10362dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6972fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cb165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536e9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54b9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dde5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(x_train[99])# i wanted to see the 100 image \n",
    "plt.colorbar()# i want to have the gradueted bar with colors\n",
    "plt.grid(False)# i dont want to have a grid on the image\n",
    "plt.xlabel(y_train[99])# write the number on the photo on x axis\n",
    "plt.show()# show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255# used for scaling of the numbers rappresenting the color of the image\n",
    "# its a good practice becouse otherwise we will operete with very large numbers and this will\n",
    "# give us problems ( overflow )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ed547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing as above ( just to see if the conversion were done correctly )\n",
    "plt.matshow(x_train[99])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.xlabel(y_train[99])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 25 training images with labels and verify that the data is in the correct formate.\n",
    "plt.figure(figsize=(10,10))# <--------------------------------------------------------------------------- UNKNOWN\n",
    "for i in range(25):# i want to plot 25 images\n",
    "    plt.subplot(5,5,i+1)# the letter \"i\" rappresent the position \n",
    "    plt.xticks([])# <------------------------------------------------------------------------------------ UNKNOWN\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)# in this way i will not have the grid in on the images\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)# load the image and make it show black and white\n",
    "    plt.xlabel(y_train[i])# add the lable associated to that image under it\n",
    "plt.show()# show all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the structure of neural network\n",
    "# (i dont know which activation function is the best for this problem same for the inner and last layer dimensions)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), # this layer will convert two dimetional (2d) array (image of 28x28 pixels) in to a one dimentional array of 28*28 = 784pixels.\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)# last layer has 10 neurons, with softmax as activation function\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06849e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of neural network \n",
    "model.compile(optimizer='adam',# we have seen it duering the lessosn\n",
    "             loss='sparse_categorical_crossentropy',# <---------------------------------------------------- UNKNOWN\n",
    "             metrics=['accuracy'])# <---------------------------------------------------------------------- UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90907093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from ann_visualizer.visualize import ann_viz;\n",
    "\n",
    "#ann_viz(model, title=\"My first neural network\")\n",
    "\n",
    "#visualizer(model, format='png', view=True)# this give us an error\n",
    "#plot_model(model, to_file='model.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad477e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training of the model \n",
    "model.fit(x_train, y_train, epochs=1)# we do the training for only one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)# test the model on our test set\n",
    "print('test accuracy:{0}\\ntest loss:{1}'.format(test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1deee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in model.layers: print(layer.get_config(), layer.get_weights())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Number of layers: {0}\".format(len(layer.get_weights())))\n",
    "print(\"First layer shape: {0}\".format(np.shape(layer.get_weights()[0])))\n",
    "#print(\"Second layer shape: {0}\".format(np.shape(layer.get_weights()[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for single images\n",
    "\n",
    "# we know that y_test[kk] image is something, we want to see if our neural networck predict it correctly\n",
    "kk = 9# image number in the training set thet we want to check\n",
    "img = x_test[kk]\n",
    "# print(img.shape)  # shape (28, 28)\n",
    "\n",
    "# tf.keras model are optimized to make predictions for batch or collection of test data at once. So we need to add it to a list:\n",
    "img_list = np.expand_dims(img,0)\n",
    "# print(img_list)   # shape (1, 28, 28)\n",
    "\n",
    "predictions_single = model.predict(img_list)# performe the prediction\n",
    "\n",
    "plt.matshow(x_test[kk])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.xlabel(\"The lable is: {0}\\nwhile the predicted value is:{1}\".format(y_test[kk], np.argmax(predictions_single)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d10dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89671bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804ee67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f27aba7de901f0b43cdce99199f8eab57e9e4bade0b8eaa2447270c05eeb2dce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
