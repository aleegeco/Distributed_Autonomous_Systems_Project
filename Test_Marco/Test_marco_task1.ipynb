{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulation, the graph is connected.\n",
      "Check Stochasticity \n",
      " row: [1. 1. 1. 1. 1. 1. 1.] \n",
      " column: [1. 1. 1. 1. 1. 1. 1.]\n",
      "Agent 0, iter = 0\n",
      "Agent 1, iter = 0\n",
      "Agent 2, iter = 0\n",
      "Agent 3, iter = 0\n",
      "Agent 4, iter = 0\n",
      "Agent 5, iter = 0\n",
      "Agent 6, iter = 0\n",
      "Agent 0, iter = 1\n",
      "Agent 1, iter = 1\n",
      "Agent 2, iter = 1\n",
      "Agent 3, iter = 1\n",
      "Agent 4, iter = 1\n",
      "Agent 5, iter = 1\n",
      "Agent 6, iter = 1\n",
      "Agent = 0, Gradient Tracking\n",
      "Agent = 1, Gradient Tracking\n",
      "Agent = 2, Gradient Tracking\n",
      "Agent = 3, Gradient Tracking\n",
      "Agent = 4, Gradient Tracking\n",
      "Agent = 5, Gradient Tracking\n",
      "Agent = 6, Gradient Tracking\n",
      "Agent 0, iter = 2\n",
      "Agent 1, iter = 2\n",
      "Agent 2, iter = 2\n",
      "Agent 3, iter = 2\n",
      "Agent 4, iter = 2\n",
      "Agent 5, iter = 2\n",
      "Agent 6, iter = 2\n",
      "Agent = 0, Gradient Tracking\n",
      "Agent = 1, Gradient Tracking\n",
      "Agent = 2, Gradient Tracking\n",
      "Agent = 3, Gradient Tracking\n",
      "Agent = 4, Gradient Tracking\n",
      "Agent = 5, Gradient Tracking\n",
      "Agent = 6, Gradient Tracking\n",
      "Agent 0, iter = 3\n",
      "Agent 1, iter = 3\n",
      "Agent 2, iter = 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  # this library will be used for data visualization\n",
    "import networkx as nx  # library for network creation/visualization/manipulation\n",
    "from Function_Task_1 import *\n",
    "\n",
    "np.random.seed(0)  # generate random number (always the same seed)\n",
    "\n",
    "PRINT = True\n",
    "FIGURE = False\n",
    "RESIZE_DATA = True\n",
    "\n",
    "# Parameters for the data size\n",
    "test_set_size = 0.1  # percentage of the test set over the entire data\n",
    "percent = 0.1  # percentage of data we want to give to our system from all the data available\n",
    "\n",
    "# chosen digit to work on\n",
    "LuckyNumber = 4\n",
    "\n",
    "# DEFINITION OF THE BINOMIAL GRAPH\n",
    "NN = 7  # number of AGENTS\n",
    "p_ER = 0.3  # spawn edge probability\n",
    "I_NN = np.identity(NN, dtype=int)  # necessary to build the Adj\n",
    "\n",
    "# Main ALGORITHM Parameters\n",
    "max_iters = 20\n",
    "stepsize = 0.1\n",
    "\n",
    "while 1:\n",
    "    Adj = np.random.binomial(1, p_ER, (NN, NN))  # create a NN x NN matrix with random connections\n",
    "    Adj = np.logical_or(Adj, Adj.T)  # makes it symmetric\n",
    "    Adj = np.multiply(Adj, np.logical_not(I_NN)).astype(int)  # removes the element on the diagonal\n",
    "\n",
    "    test = np.linalg.matrix_power((I_NN + Adj), NN)  # necessary condition to check if the graph is connected\n",
    "\n",
    "    if np.all(test > 0):  # here he tests if the matrix that he created is connected\n",
    "        if PRINT: print(\"Congratulation, the graph is connected.\")\n",
    "        break\n",
    "    else:\n",
    "        if PRINT: print(\"Warning, the graph is NOT connected.\")\n",
    "        quit()\n",
    "\n",
    "#                                       Compute mixing matrices\n",
    "#                     Metropolis-Hastings method to obtain a doubly-stochastic matrix\n",
    "\n",
    "WW = np.zeros((NN, NN))\n",
    "\n",
    "for ii in range(NN):\n",
    "    N_ii = np.nonzero(Adj[ii])[0]  # In-Neighbors of node i\n",
    "    deg_ii = len(N_ii)\n",
    "\n",
    "    for jj in N_ii:\n",
    "        N_jj = np.nonzero(Adj[jj])[0]  # In-Neighbors of node j\n",
    "        # deg_jj = len(N_jj)\n",
    "        deg_jj = N_jj.shape[0]\n",
    "\n",
    "        WW[ii, jj] = 1 / (1 + max([deg_ii, deg_jj]))\n",
    "        # WW[ii,jj] = 1/(1+np.max(np.stack((deg_ii,deg_jj)) ))\n",
    "\n",
    "WW += I_NN - np.diag(np.sum(WW, axis=0))\n",
    "\n",
    "if PRINT: print('Check Stochasticity \\n row: {} \\n column: {}'.format(np.sum(WW, axis=1), np.sum(WW, axis=0)))\n",
    "\n",
    "# Creating the Graph g\n",
    "G = nx.from_numpy_array(Adj)\n",
    "if FIGURE: nx.draw(G, with_labels=True, font_weight='bold', node_color='orange', node_size=800)\n",
    "\n",
    "# Data acquisition and processing\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# adjusting the type of the data contained in the arrays in this way they can be also negative\n",
    "y_train = y_train.astype(np.int8)\n",
    "y_test = y_test.astype(np.int8)\n",
    "\n",
    "# scale the brightness of each pixel because otherwise saturates the activation function\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Reducing the datas if required\n",
    "if RESIZE_DATA:\n",
    "    x_total_temp = np.append(x_train, x_test, axis=0)\n",
    "    x_total = x_total_temp[0: int(np.shape(x_total_temp)[0] * percent)]\n",
    "    y_total_temp = np.append(y_train, y_test, axis=0)\n",
    "    y_total = y_total_temp[0: int(np.shape(y_total_temp)[0] * percent)]\n",
    "\n",
    "    # Random redistribution of the data in two sets ( test and train)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_total, y_total, test_size=test_set_size)\n",
    "\n",
    "# we associate -1 to data which not represent the number we want to calssify\n",
    "for i in range(0, np.shape(y_train)[0]):\n",
    "    if y_train[i] == LuckyNumber:\n",
    "        y_train[i] = 1\n",
    "    else:\n",
    "        y_train[i] = 0\n",
    "\n",
    "for i in range(0, np.shape(y_test)[0]):\n",
    "    if y_test[i] == LuckyNumber:\n",
    "        y_test[i] = 1\n",
    "    else:\n",
    "        y_test[i] = 0\n",
    "\n",
    "# visualize some images of the dataset with the new labels\n",
    "if FIGURE:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(y_train[i])\n",
    "        plt.show()\n",
    "\n",
    "    # Reshape of the input data from a matrix [28 x 28] to a vector [ 784 x 1 ]\n",
    "x_train_vct = np.reshape(x_train, (x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n",
    "x_test_vct = np.reshape(x_test, (x_test.shape[0], x_test.shape[1] * x_test.shape[2]))\n",
    "\n",
    "# MANCA LA PARTE DI BILANCIAMENTO DEL DATASET\n",
    "## We split the dataset for each agent\n",
    "# dim_train_agent = np.shape(x_train_vct)[0]//NN\n",
    "# dim_test_agent = np.shape(x_test_vct)[0]//NN\n",
    "\n",
    "dim_train_agent = 40  # impose the number of images\n",
    "dim_test_agent = 40\n",
    "\n",
    "data_point = np.zeros((NN, dim_train_agent, np.shape(x_train_vct)[1]))\n",
    "label_point = np.zeros((NN, dim_train_agent))\n",
    "\n",
    "data_test = np.zeros((NN, dim_test_agent, np.shape(x_test_vct)[1]))\n",
    "label_test = np.zeros((NN, dim_test_agent))\n",
    "\n",
    "# data_validation, label_validation\n",
    "\n",
    "for agent in range(NN):\n",
    "    agent_index = agent * dim_train_agent + np.arange(dim_train_agent)\n",
    "    data_point[agent, :, :] = x_train_vct[agent_index, :]\n",
    "    label_point[agent, :] = y_train[agent_index]\n",
    "\n",
    "    agent_index = agent * dim_test_agent + np.arange(dim_test_agent)\n",
    "    data_test[agent, :, :] = x_test_vct[agent_index, :]\n",
    "    label_test[agent, :] = y_test[agent_index]\n",
    "\n",
    "#  Set Up the Neural Network\n",
    "\n",
    "d = [784, 784, 784, 784]\n",
    "T = len(d)  # how much layer we have\n",
    "dim_layer = d[0]  # number of neurons considering bias\n",
    "\n",
    "                                    ## ALGORITHM ##\n",
    "\n",
    "uu = np.zeros((NN, max_iters, T - 1, dim_layer, dim_layer + 1))  # +1 means bias\n",
    "uu[:,0,:,:,:] = np.random.randn(NN, T-1, dim_layer, dim_layer +1)\n",
    "yy = np.zeros((NN, max_iters, T - 1, dim_layer, dim_layer + 1))\n",
    "grad_u = np.zeros((NN, max_iters, T - 1, dim_layer, dim_layer + 1))  # +1 means bias\n",
    "\n",
    "# force the last layer to have a 1Ã¹\n",
    "# uu[agent, iteration, layer, neuron, neuron + bias]\n",
    "uu[:, :, -1, 0] = 1\n",
    "JJ = np.zeros((NN, max_iters))\n",
    "\n",
    "## ITERATION 0 - Initialization of Gradient of u\n",
    "\n",
    "for agent in range(NN):\n",
    "    print(\"Agent {}, iter = {}\".format(agent, 0))\n",
    "    for image in range(dim_train_agent):\n",
    "        temp_data = data_point[agent, image, :]\n",
    "        temp_label = label_point[agent, image]\n",
    "\n",
    "        temp_data_test = data_test[agent, image, :]\n",
    "        temp_label_test = label_test[agent, image]\n",
    "\n",
    "        xx = forward_pass(uu[agent, 0], temp_data, T, dim_layer)\n",
    "        xx_test = forward_pass(uu[agent, 0], temp_data_test, T, dim_layer)\n",
    "\n",
    "        _, lambda_T = cost_function(xx[-1], temp_label)\n",
    "        JJ_temp, _ = cost_function(xx_test[-1], temp_label_test)\n",
    "        JJ[agent, 0] += JJ_temp\n",
    "\n",
    "        delta_u = backward_pass(xx, uu[agent, 0], lambda_T, T, dim_layer)\n",
    "\n",
    "        for layer in range(T - 1):\n",
    "            grad_u[agent, 0, layer] += delta_u[layer] / (np.shape(temp_data)[0])\n",
    "            yy[agent, 0, layer] += delta_u[layer] / (np.shape(temp_data)[0])\n",
    "\n",
    "    for layer in range(T - 1):\n",
    "        uu[agent, 1, layer] += WW[agent, agent] * uu[agent, 0, layer] - stepsize * grad_u[agent, 0, layer]\n",
    "\n",
    "# ALGORITHM STARTING FROM k = 1\n",
    "for iter in range(1, max_iters - 1):\n",
    "    for agent in range(NN):\n",
    "        print(\"Agent {}, iter = {}\".format(agent, iter))\n",
    "        for image in range(dim_train_agent):\n",
    "            temp_data = data_point[agent, image, :]\n",
    "            temp_label = label_point[agent, image]\n",
    "\n",
    "            temp_data_test = data_test[agent, image, :]\n",
    "            temp_label_test = label_test[agent, image]\n",
    "\n",
    "            xx = forward_pass(uu[agent, iter], temp_data, T, dim_layer)\n",
    "            xx_test = forward_pass(uu[agent, iter], temp_data_test, T, dim_layer)\n",
    "\n",
    "            _, lambda_T = cost_function(xx[-1], temp_label)\n",
    "            JJ_temp, _ = cost_function(xx_test[-1], temp_label_test)\n",
    "            JJ[agent, iter] += JJ_temp\n",
    "\n",
    "            delta_u = backward_pass(xx, uu[agent, iter], lambda_T, T, dim_layer)\n",
    "            for layer in range(T - 1):\n",
    "                grad_u[agent, iter, layer] += delta_u[layer] / (np.shape(temp_data)[0])\n",
    "\n",
    "    ## Gradient Tracking\n",
    "    for agent in range(NN):\n",
    "        print(\"Agent = {}, Gradient Tracking\".format(agent))\n",
    "        for layer in range(T - 1):\n",
    "            delta_grad_u = grad_u[agent, iter, layer] - grad_u[agent, iter - 1, layer]\n",
    "            yy[agent, iter, layer] = WW[agent, agent] * yy[agent, iter - 1, layer] + delta_grad_u\n",
    "\n",
    "            for neigh in G.neighbors(agent):\n",
    "                yy[agent, iter, layer] = WW[agent, neigh] * yy[neigh, iter - 1, layer]\n",
    "\n",
    "            uu[agent, iter + 1, layer] = WW[agent, agent] * uu[agent, iter, layer] - stepsize * yy[agent, iter, layer]\n",
    "\n",
    "            for neigh in G.neighbors(agent):\n",
    "                uu[agent, iter + 1, layer] += WW[agent, neigh] * uu[neigh, iter, layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.plot(range(max_iters-1), (JJ[0,:-1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(max_iters), grad_u[0, :, -2, 1, 10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}